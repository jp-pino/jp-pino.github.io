<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="description" content="Comments on paper from IEEE Transactions on Image Processing">

    <meta property="og:title" content="Image Processing | Juan Pablo Pino" />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://jp-pino.github.io/blog/ieee-comments" />
    <meta property="og:description" content="Comments on paper from IEEE Transactions on Image Processing" />

    <title>Image Processing | Juan Pablo Pino</title>

    <link rel="home" href="https://jp-pino.github.io/">
    <link rel="icon" href="/favicon.ico">
    <link href="/blog/feed.atom" type="application/atom+xml" rel="alternate" title="Juan Pablo Pino Atom Feed">

        <!-- Insert analytics code here -->
    
    <link href="https://fonts.googleapis.com/css?family=Nunito+Sans:300,300i,400,400i,700,700i,800,800i" rel="stylesheet">
    <script src="https://kit.fontawesome.com/3edb0a22e7.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="/assets/build/css/main.css?id=7b4cf1fc63b42313749d4f4ae9f53d89">
</head>

<body class="flex flex-col justify-between min-h-screen bg-gray-100 text-gray-800 leading-normal font-sans">
    <header class="flex items-center shadow bg-white border-b h-24 py-4" role="banner">
        <div class="container flex items-center max-w-8xl mx-auto px-4 lg:px-8">
            <div class="flex items-center">
                <a href="/" title="Juan Pablo Pino home" class="inline-flex items-center">
                    <img class="h-8 md:h-12 mr-1" src="/assets/img/logo.png" alt="Juan Pablo Pino logo" />

                    <h1 class="text-lg md:text-2xl text-blue-800 font-semibold hover:text-blue-600 my-0">Juan Pablo Pino</h1>
                </a>
            </div>

            <div id="vue-search" class="flex flex-1 justify-end items-center">
                <search></search>

                <nav class="hidden lg:flex items-center justify-end text-lg">
    <a title="Juan Pablo Pino Blog" href="/blog" class="ml-6 text-gray-700 hover:text-blue-600 ">
        Blog
    </a>

    <a title="Juan Pablo Pino About" href="/about" class="ml-6 text-gray-700 hover:text-blue-600 ">
        About
    </a>

    <a title="Juan Pablo Pino Contact" href="/contact" class="ml-6 text-gray-700 hover:text-blue-600 ">
        Contact
    </a>
</nav>

                <button class="flex justify-center items-center bg-blue-500 border border-blue-500 h-10 px-5 rounded-full lg:hidden focus:outline-none"
    onclick="navMenu.toggle()"
>
    <svg id="js-nav-menu-show" xmlns="http://www.w3.org/2000/svg"
        class="fill-current text-white h-9 w-4" viewBox="0 0 32 32"
    >
        <path d="M4,10h24c1.104,0,2-0.896,2-2s-0.896-2-2-2H4C2.896,6,2,6.896,2,8S2.896,10,4,10z M28,14H4c-1.104,0-2,0.896-2,2  s0.896,2,2,2h24c1.104,0,2-0.896,2-2S29.104,14,28,14z M28,22H4c-1.104,0-2,0.896-2,2s0.896,2,2,2h24c1.104,0,2-0.896,2-2  S29.104,22,28,22z"/>
    </svg>

    <svg id="js-nav-menu-hide" xmlns="http://www.w3.org/2000/svg"
        class="hidden fill-current text-white h-9 w-4" viewBox="0 0 36 30"
    >
        <polygon points="32.8,4.4 28.6,0.2 18,10.8 7.4,0.2 3.2,4.4 13.8,15 3.2,25.6 7.4,29.8 18,19.2 28.6,29.8 32.8,25.6 22.2,15 "/>
    </svg>
</button>

            </div>
        </div>
    </header>

    <nav id="js-nav-menu" class="w-auto px-2 pt-6 pb-2 bg-gray-200 shadow hidden lg:hidden">
    <ul class="my-0">
        <li class="pl-4">
            <a
                title="Juan Pablo Pino Blog"
                href="/blog"
                class="block mt-0 mb-4 text-sm no-underline text-gray-800 hover:text-blue-500"
            >Blog</a>
        </li>
        <li class="pl-4">
            <a
                title="Juan Pablo Pino About"
                href="/about"
                class="block mt-0 mb-4 text-sm no-underline text-gray-800 hover:text-blue-500"
            >About</a>
        </li>
        <li class="pl-4">
            <a
                title="Juan Pablo Pino Contact"
                href="/contact"
                class="block mt-0 mb-4 text-sm no-underline text-gray-800 hover:text-blue-500"
            >Contact</a>
        </li>
    </ul>
</nav>

    <main role="main" class="flex-auto w-full container max-w-4xl mx-auto py-16 px-6">
                    <img src="/assets/img/ieee-computer-vision.png" alt="Image Processing cover image" class="mb-2">
    
    <h1 class="leading-none mb-2">Image Processing</h1>

    <p class="text-gray-700 text-xl md:mt-0">Juan Pablo Pino  •  August 18, 2019</p>

                        <a
                href="/blog/categories/homework"
                title="View posts in homework"
                class="inline-block bg-gray-300 hover:bg-blue-200 leading-loose tracking-wide text-gray-800 uppercase text-xs font-semibold rounded mr-4 px-3 pt-px"
            >homework</a>
                    <a
                href="/blog/categories/robotic-vision"
                title="View posts in robotic-vision"
                class="inline-block bg-gray-300 hover:bg-blue-200 leading-loose tracking-wide text-gray-800 uppercase text-xs font-semibold rounded mr-4 px-3 pt-px"
            >robotic-vision</a>
            
    <div class="border-b border-blue-200 mb-10 pb-4" v-pre>
        <h3>Panoramic Images</h3>

<p><em>Comments on <a href="https://ieeexplore.ieee.org/document/7362211"><strong>"Real-Time Panoramic Image Generation and Motion Deblurring by Using Dynamics-Based Robotic Vision"</strong></a> by Michael Duckjune Kim &amp; Jun Ueda from <a href="https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7463574">"IEEE/ASME Transactions on Mechatronics Vol. 21"</a></em></p>

<p>Out of all the papers I've read for this assignment, this one is the most related to robotics. The method this paper proposes for panoramic image stitching differs from the traditional methods in that the pictures are taken as the camera moves, instead of waiting to capture the image before the camera starts moving. The following diagram from the paper illustrates this:</p>

<blockquote>
  <p><img src="/assets/img/ieee-panoramic-diagram.png" alt="alt text" /></p>
  
  <p>Timeline to create a panoramic image from VGA images. The “move” block represents the settling time for a point-to-point motion using the robotic vision system. The “image” block represent the time of image acquisition. The “de” block represents the computation time of image deblurring that was set to 16.5 ms based on the results from Section IV-D.</p>
</blockquote>

<p>The proposed method is not only very time-efficient, but it also produces very good results. The actual implementation of this paper involves not only understanding of images and robotics, but interfacing between them too.</p>

<h3>Atmospheric Visibility Estimation</h3>

<p><em>Comments on <a href="https://ieeexplore.ieee.org/document/8412582"><strong>"Relative CNN-RNN: Learning Relative Atmospheric Visibility From Images"</strong></a> by Yang You &amp; Cewu Lu from <a href="https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8468142&amp;punumber=83">"IEEE Transactions on Image Processing Vol. 28"</a></em></p>

<p>Reading this paper, it becomes clear that image processing is a field that may have far-reaching impacts on our lives. This paper proposes a method for estimating relative visibility from images using a relative CNN-RNN model. According to the paper, this model combines a Convolutional Neural Networks with a Recursive Neural Network which allows it to analyze the images with seven different attention regions in the images. As the authors mention, this approach produces good results in atmospheric visibility estimation and if implemented in a large-scale setup (e.g. using geo-tagged images uploaded to the web), it becomes much more affordable than the expensive scientific equipment used in very sparse weather observatories. <strong><em>Image processing</em></strong> and <strong><em>Robotic Vision</em></strong>, are clearly fields that offer new and innovative solutions to everyday problems today. However, when combined with other fields such as Data Science and Machine Learning, the solutions they offer become something out of a sci-fi movie.</p>

<h3>Object Counting</h3>

<p><em>Comments on <a href="https://ieeexplore.ieee.org/document/8488575"><strong>"Divide and Count: Generic Object Counting by Image Divisions"</strong></a> by Tobias Stahl, Silvia L. Pintea &amp; Jan C. van Gemert from <a href="https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8478029&amp;punumber=83">"IEEE Transactions on Image Processing Vol. 28"</a></em></p>

<p>This paper proposes a method for generic object counting in images. From previous experiences, we can tell that objecting counting is essential for industrial applications, but as the paper mentions, emerging applications include fauna monitoring, traffic control, crowd management, etc. Similarly to the previous paper, the authors of this one use <strong><em>Data Science</em></strong> and <strong><em>Machine Learning</em></strong> to implement innovative solutions in the field of <strong><em>Image Processing</em></strong>. It becomes clear that these fields are becoming intertwined as research advances. The most common object counting applications however, have been constrained by the type of object that is being counted. There are car counting systems. There are fruit counting systems. There are pill counting systems. But all these systems work independently, are trained individually and only work for the specific object they were trained to count. I find the proposal in this paper appealing, because a system that can reliably count objects of any type, is more portable to other applications and can improve new and existing systems without investing too much effort on training.</p>

<h3>Underwater Image Enhancement</h3>

<p><em>Comments on <a href="https://ieeexplore.ieee.org/document/8058463"><strong>"Color Balance and Fusion for Underwater Image Enhancement"</strong></a> by Codruta O. Ancuti, Cosmin Ancuti, Christophe De Vleeschouwer, &amp; Philippe Bekaert from <a href="https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8071125&amp;punumber=83">"IEEE Transactions on Image Processing Vol. 27"</a></em></p>

<p>I found this paper really interesting because the solution it proposes relates to an issue I (and many of us) have personally faced. Ever since the first waterproof cameras came out, underwater photography has faced many issues. Any camera can take a great picture on land, however light propagates differently underwater and thus distorts the shapes and colors in our images. Without special equipment or expensive hardware, the authors have developed a method to correct these distortions and generate an accurate image using only software. Their solution is pretty straightforward and, unlike the previous two papers, it has nothing to do with machine learning. It implements a pipeline of <em>only</em> image processing that produces amazing results.</p>

<h3>Image Deblurring</h3>

<p><em>Comments on <a href="https://ieeexplore.ieee.org/document/8488519"><strong>"Graph-Based Blind Image Deblurring From a Single Photograph"</strong></a> by Yuanchao Bai, Gene Cheung, Xianming Liu, &amp; Wen Gao from <a href="https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8511005&amp;punumber=83">"IEEE Transactions on Image Processing Vol. 28"</a></em></p>

<p>This paper describes the method implemented by the authors to deblur images. I don't pretend to understand everything the paper explains in regard to their algorithm, but I get the base of it. In order to get the original image they iteratively estimate the blur kernel and use it to calculate a skeleton image, until both the blur kernel and the image no longer change. I found this paper very interesting and was impressed by the very realistic results they show. The images resulting from their algorithm clearly show an deblurred version of the original. This could have countless practical applications and I think is a very good example of what <em><strong>Image Processing</strong></em> entails: both understanding of how computers perceive images, and of other fields of math and science such as <em><strong>Probability</strong></em> and <em><strong>Linear Algebra</strong></em>.</p>
    </div>

    <nav class="flex justify-between text-sm md:text-base">
        <div>
                            <a href="https://jp-pino.github.io/blog/mopiOS" title="Older Post: mopiOS">
                    &LeftArrow; mopiOS
                </a>
                    </div>

        <div>
                            <a href="https://jp-pino.github.io/blog/aes-file-encryption" title="Newer Post: AES">
                    AES &RightArrow;
                </a>
                    </div>
    </nav>
    </main>

    <footer class="bg-white text-center text-sm mt-12 py-4" role="contentinfo">
        <ul class="flex flex-col md:flex-row justify-center list-none">
            <li>
                Made with <i class="fa-solid fa-heart" style="color: #ff2600;"></i> by Juan Pablo Pino
            </li>
        </ul>
    </footer>

    <script src="/assets/build/js/main.js?id=d7116c1832f1f0caf2f77e815b455524"></script>
    <script>
    const navMenu = {
        toggle() {
            const menu = document.getElementById('js-nav-menu');
            menu.classList.toggle('hidden');
            menu.classList.toggle('lg:block');
            document.getElementById('js-nav-menu-hide').classList.toggle('hidden');
            document.getElementById('js-nav-menu-show').classList.toggle('hidden');
        },
    }
</script>
</body>

</html>
